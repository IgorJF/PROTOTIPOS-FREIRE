{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"URL_DO_SEU_SISTEMA_AQUI\"\n",
    "# response = requests.get(url)\n",
    "# html_content = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# tabela_proteses = soup.find(\"table\", {\"class\": \"classe_da_tabela\"})\n",
    "# linhas = tabela_proteses.find_all(\"tr\")\n",
    "\n",
    "# for linha in linhas:\n",
    "#     colunas = linha.find_all(\"td\")\n",
    "#     nome = colunas[0].text\n",
    "#     situacao = colunas[1].text\n",
    "#     doutor = colunas[2].text\n",
    "#     data = colunas[3].text\n",
    "\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# lista_proteses = soup.find(\"ul\", {\"class\": \"lista-proteses\"})\n",
    "# itens = lista_proteses.find_all(\"li\")\n",
    "\n",
    "# for item in itens:\n",
    "#     nome = item.text\n",
    "\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# div_proteses = soup.find(\"div\", {\"class\": \"classe-da-div\"})\n",
    "\n",
    "# paragrafos = soup.find_all(\"p\")\n",
    "# for paragrafo in paragrafos:\n",
    "#     print(paragrafo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import gspread\n",
    "# from google.oauth2.credentials import Credentials\n",
    "\n",
    "# # URL do site\n",
    "# url = \"https://igorjf.github.io/TESTE-WEBSCRAPPING/\"\n",
    "\n",
    "# # Realiza a requisição GET para obter o conteúdo da página\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # Verifica se a requisição foi bem-sucedida\n",
    "# if response.status_code == 200:\n",
    "#     # Parseia o conteúdo HTML\n",
    "#     soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "#     # Encontra todas as divs com a classe \"protese\"\n",
    "#     divs_prot = soup.find_all(\"div\", class_=\"protese\")\n",
    "    \n",
    "#     # Lista para armazenar os dados\n",
    "#     data = []\n",
    "\n",
    "#     # Itera sobre cada div com a classe \"protese\"\n",
    "#     for div in divs_prot:\n",
    "#         # Encontra todos os elementos p dentro da div\n",
    "#         elements = div.find_all(\"p\")\n",
    "        \n",
    "#         # Extrai os dados relevantes\n",
    "#         protocolo = elements[0].text\n",
    "#         data_protocolo = elements[1].text\n",
    "#         paciente = elements[2].text\n",
    "#         arcada = elements[3].text\n",
    "#         descricao = elements[4].text\n",
    "#         dentista = elements[5].text\n",
    "#         protetico = elements[6].text\n",
    "#         envio = elements[7].text\n",
    "#         data_solicitada = elements[8].text\n",
    "#         data_recebida = elements[9].text\n",
    "        \n",
    "#         # Adiciona os dados à lista\n",
    "#         data.append([data_protocolo, protocolo, paciente, arcada, descricao, dentista, protetico, envio, data_solicitada, data_recebida])\n",
    "\n",
    "#     # Cria um DataFrame pandas com os dados raspados\n",
    "#     df_novos = pd.DataFrame(data, columns=[\"Data da Criação da OS\", \"Número da OS\", \"Paciente\", \"Arcada ou Unitário\", \"Descrição do Trabalho\", \"Dentista Solicitante\", \"Protético\", \"Data do Envio para Protético\", 'Data \"SOLICITADA PARA RETORNO DO TRABALHO DO PROTÉTICO\"', \"Data Recebimento\"])\n",
    "\n",
    "#     # Autenticar e abrir a planilha do Google Sheets\n",
    "#     creds = Credentials.from_authorized_user_file('credentials.json')\n",
    "#     gc = gspread.authorize(creds)\n",
    "#     worksheet = gc.open(\"Controle Odonto - Gestão Prótes\").worksheet(\"TESTE AUTOMAÇÃO - MATRIZ - Logistica Prótese\")\n",
    "\n",
    "#     # Adicionar dados ao Google Sheets\n",
    "#     for i, row in df_novos.iterrows():\n",
    "#         worksheet.append_row(row.tolist())\n",
    "\n",
    "#     print(\"Dados adicionados com sucesso!\")\n",
    "# else:\n",
    "#     print(\"Falha ao acessar o site.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL do site\n",
    "url = \"https://igorjf.github.io/TESTE-WEBSCRAPPING/\"\n",
    "\n",
    "# Realiza a requisição GET para obter o conteúdo da página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code == 200:\n",
    "    # Parseia o conteúdo HTML\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Encontra todas as divs com a classe \"protese\"\n",
    "    divs_prot = soup.find_all(\"div\", class_=\"protese\")\n",
    "    \n",
    "    # Lista para armazenar os dados\n",
    "    data = []\n",
    "\n",
    "    # Itera sobre cada div com a classe \"protese\"\n",
    "    for div in divs_prot:\n",
    "        # Encontra todos os elementos p dentro da div\n",
    "        elements = div.find_all(\"p\")\n",
    "        \n",
    "        # Extrai os dados relevantes\n",
    "        protocolo = elements[0].text\n",
    "        data_protocolo = elements[1].text\n",
    "        paciente = elements[2].text\n",
    "        arcada = elements[3].text\n",
    "        descricao = elements[4].text\n",
    "        dentista = elements[5].text\n",
    "        protetico = elements[6].text\n",
    "        envio = elements[7].text\n",
    "        data_solicitada = elements[8].text\n",
    "        data_recebida = elements[9].text\n",
    "        \n",
    "        # Adiciona os dados à lista\n",
    "        data.append([data_protocolo, protocolo, paciente, arcada, descricao, dentista, protetico, envio, data_solicitada, data_recebida])\n",
    "\n",
    "    # Cria um DataFrame pandas com os dados raspados\n",
    "    df_novos = pd.DataFrame(data, columns=[\"Data da Criação da OS\", \"Número da OS\", \"Paciente\", \"Arcada ou Unitário\", \"Descrição do Trabalho\", \"Dentista Solicitante\", \"Protético\", \"Data do Envio para Protético\", 'Data \"SOLICITADA PARA RETORNO DO TRABALHO DO PROTÉTICO\"', \"Data Recebimento\"])\n",
    "\n",
    "    # Carrega a planilha existente\n",
    "    try:\n",
    "        # Leia todas as planilhas do arquivo Excel\n",
    "        xl = pd.ExcelFile(\"TESTE AUTOMAÇÃO - MATRIZ - Logistica Prótese.xlsx\")\n",
    "        \n",
    "        # Adicione as novas informações ao final do DataFrame existente na planilha específica\n",
    "        df_existente = pd.read_excel(xl, sheet_name=\"Controle Odonto - Gestão Prótes\")\n",
    "\n",
    "        df_atualizado = pd.concat([df_existente, df_novos], ignore_index=True)\n",
    "\n",
    "        # Salva os dados atualizados na mesma planilha específica\n",
    "        with pd.ExcelWriter(\"TESTE AUTOMAÇÃO - MATRIZ - Logistica Prótese.xlsx\") as writer:\n",
    "            df_atualizado.to_excel(writer, sheet_name=\"Controle Odonto - Gestão Prótes\", index=False)\n",
    "\n",
    "        print(\"Dados adicionados com sucesso!\")\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao carregar ou salvar a planilha existente:\", e)\n",
    "else:\n",
    "    print(\"Falha ao acessar o site.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
